{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6213fe7c-dd70-4033-ba8b-6282db91216a",
   "metadata": {},
   "source": [
    "### Brand var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be92c12-8a24-4494-bb96-bcd6ec79a1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brand = 'cerave'\n",
    "path_to_chromedriver = 'C:/Users/gianhubinh.le/Driver/chromedriver32.exe'\n",
    "path_to_chromebrowser = 'C:/Users/gianhubinh.le/chrome-win64/chrome.exe'\n",
    "path_to_userdata = 'C:/Users/gianhubinh.le/AppData/Local/Google/Chrome for Testing/User Data'\n",
    "file_download_path = 'C:\\\\Users\\\\gianhubinh.le\\\\Downloads'\n",
    "# file_save_path = \"C:/Users/gianhubinh.le/OneDrive - L'Oréal/Tiktok data\"\n",
    "file_save_path = \"C:/Users/gianhubinh.le/OneDrive - L'Oréal/Documents - -VN- Data Hub - Analytics/Tiktok Shop/Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d42ba-f6ba-4022-be61-b639d089bb37",
   "metadata": {},
   "source": [
    "## 1. Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8594d37-085a-4a58-aa7c-999037fa1f26",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import xlsxwriter\n",
    "import selenium\n",
    "import time\n",
    "import urllib3\n",
    "import requests\n",
    "import pandas as pd\n",
    "import ipynb\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta, MO\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b27ba-68b5-4575-8bfb-4c0faed5bd41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Make a date table (scrape date and timestamp to scrape)\n",
    "\n",
    "Note for users: You must input 3 variables \n",
    "1. Start time for scraping \n",
    "2. End time for scraping \n",
    "3. Domain of scraping (1 => livestream, 2 => video, 3 => order, 4 => affiliate order) \\\n",
    "Example: '1,2,3' => scrape all livestream, video, order, '1' => scrape only livestream\n",
    "\n",
    "Note for developer: \\\n",
    "1688212800 (1/7/2023) => all data of june \\\n",
    "1685620800 (1/6/2023) => all data of may"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2eebee4-3431-46cf-95de-3f8bc5a3eb16",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_date = datetime.datetime.now()\n",
    "start_date = current_date.replace(day=1).date()\n",
    "end_date = (current_date - timedelta(days=1)).date()\n",
    "# Format the dates as strings in \"yyyy-mm-dd\" format\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "domain = '12345'\n",
    "\n",
    "x = start_date\n",
    "\n",
    "calendar_dict = {'date_scrape': []\n",
    "                 ,'unix_time': []\n",
    "                 ,'unix_time_order_start': []\n",
    "                ,'unix_time_order_end': []}\n",
    "\n",
    "df_time = pd.DataFrame(calendar_dict)\n",
    "df_time['unix_time'] = df_time['unix_time'].astype(int)\n",
    "df_time['unix_time_order_start'] = df_time['unix_time_order_start'].astype(int)\n",
    "df_time['unix_time_order_end'] = df_time['unix_time_order_end'].astype(int)\n",
    "\n",
    "while x <= end_date:\n",
    "    \n",
    "    # create a timestamp value corresponding to the date scrape (applicable to livestream + vid)\n",
    "    y = x + relativedelta(days=+1)\n",
    "    dt1 = datetime.datetime.combine(y, datetime.time.min)\n",
    "    dt2 = dt1 + timedelta(hours=7)\n",
    "    timestamp_ver1 = round(dt2.timestamp())\n",
    "    \n",
    "    # create a timestamp value corresponding to the date scrape (applicable to order)\n",
    "    dt3 = datetime.datetime.combine(x, datetime.time.min)\n",
    "    dt4 = dt3 + timedelta(hours=23) + timedelta(minutes=59)+ timedelta(seconds=59)\n",
    "    timestamp_ver2 = round(dt3.timestamp())\n",
    "    timestamp_ver3 = round(dt4.timestamp())\n",
    "    \n",
    "    # append new row to calendar\n",
    "    row = {'date_scrape': x, 'unix_time': int(timestamp_ver1)\n",
    "           , 'unix_time_order_start': int(timestamp_ver2), 'unix_time_order_end': int(timestamp_ver3)\n",
    "          }\n",
    "    row_df = pd.DataFrame(row, index = [1])\n",
    "    df_time = pd.concat([df_time,row_df], ignore_index=True)\n",
    "\n",
    "    x = x + relativedelta(days=+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d9be2-c74c-44cd-9ed6-cb98bcba4b76",
   "metadata": {},
   "source": [
    "## 3. Renew cookie function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809fc75-aa6e-4233-bedd-2bedb1e40392",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = Service(path_to_chromedriver)\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.binary_location = path_to_chromebrowser\n",
    "options.add_argument('--user-data-dir={}'.format(path_to_userdata))\n",
    "options.add_argument('--profile-directory=Profile 1')\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument('--disable-infobars')\n",
    "\n",
    "driver = webdriver.Chrome(service = s, options=options)\n",
    "driver.get('https://seller-vn.tiktok.com/order?selected_sort=6&tab=all')\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 50).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"homepage_menu_submenu_3\"]/div/div[1]/span[1]/div/div[2]')))\n",
    "\n",
    "    cookies_lst = driver.get_cookies()\n",
    "\n",
    "    for i in cookies_lst:\n",
    "        if i['name'] == 'sid_guard_tiktokseller':\n",
    "            x = i['value'] \n",
    "        elif i['name'] == 'user_oec_info':  \n",
    "            y = i['value'] \n",
    "\n",
    "    cookies_new = {\n",
    "        'sid_guard_tiktokseller': x,\n",
    "        'user_oec_info': y\n",
    "    }\n",
    "\n",
    "    with open(\"cookies_cerave.json\", \"w\") as f:\n",
    "        json.dump(cookies_new, f)\n",
    "        \n",
    "    print('------------------------------')\n",
    "    print('Cookies is usable')\n",
    "    print('------------------------------')\n",
    "    \n",
    "except:\n",
    "    print('------------------------------')\n",
    "    print('Cookies is expired, must renew')\n",
    "    driver.get('https://seller-vn.tiktok.com/account/login')\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"TikTok_Ads_SSO_Login_Email_Panel_Button\"]').click()\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"TikTok_Ads_SSO_Login_Email_Input\"]').send_keys('123')\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"TikTok_Ads_SSO_Login_Pwd_Input\"]').send_keys('123')\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"TikTok_Ads_SSO_Login_Btn\"]').click()\n",
    "    element = WebDriverWait(driver, 100).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"top_nav_menu_compass_v2\"]')))\n",
    "    \n",
    "    cookies_lst = driver.get_cookies()\n",
    "\n",
    "    for i in cookies_lst:\n",
    "        if i['name'] == 'sid_guard_tiktokseller':\n",
    "            x = i['value'] \n",
    "        elif i['name'] == 'user_oec_info':  \n",
    "            y = i['value'] \n",
    "\n",
    "    cookies_new = {\n",
    "        'sid_guard_tiktokseller': x,\n",
    "        'user_oec_info': y\n",
    "    }\n",
    "\n",
    "    with open(\"cookies_cerave.json\", \"w\") as f:\n",
    "        json.dump(cookies_new, f)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------#\n",
    "    print('Cookies renew completed')\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f542d4-6a94-44a8-a487-fda48d97dea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Create a function to get raw data with cookies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f5319-42b2-4417-b7f9-b2e8a47f022c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4a. Func1: get order data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07969163-b49a-444a-98e2-ea179cbc8f54",
   "metadata": {},
   "source": [
    "4a1. Download excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f477d3a-8135-4c91-ba7d-6fc36c074f8c",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Order export completed\n",
      "2. Order download completed\n"
     ]
    }
   ],
   "source": [
    "start = min(df_time['unix_time_order_start'])\n",
    "end = max(df_time['unix_time_order_end'])\n",
    "link = f'https://seller-vn.tiktok.com/order?selected_sort=6&tab=all&time_order_created[]={start}&time_order_created[]={end}'\n",
    "driver.get(link)\n",
    "time.sleep(6)\n",
    "# 1. Click export\n",
    "WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"order_export_bar\"]/div/button[1]'))).click()\n",
    "time.sleep(6)\n",
    "WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, \"//span[normalize-space()='Export']\"))).click()\n",
    "time.sleep(6)\n",
    "print('1. Order export completed')\n",
    "# 2. Click download\n",
    "while True: \n",
    "    if str(WebDriverWait(driver, 1000).until(EC.visibility_of_element_located((By.XPATH, '//div//div//div//div//div//div//div//div//div[2]//button[1]//div[1]'))).text) != 'Download':\n",
    "        pass\n",
    "    else: break\n",
    "WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.XPATH, '//div//div//div//div//div//div//div//div//div[2]//button[1]//div[1]'))).click()\n",
    "if len(df_time) <= 10:\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    time.sleep(10)\n",
    "print('2. Order download completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d336e-ef2d-4b3c-8edc-72c6cf391ed6",
   "metadata": {
    "tags": []
   },
   "source": [
    "4a2. Locate to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8cbf12f-5f3e-4405-a686-2adc43ab7304",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the list of all CSV files in the current directory\n",
    "csv_files = glob.glob(file_download_path + '/*.csv')\n",
    "\n",
    "# # Get the most recently downloaded CSV file\n",
    "most_recent_file = max(csv_files, key=os.path.getctime)\n",
    "\n",
    "# # Print the name of the most recently downloaded CSV file\n",
    "df_order = pd.read_csv(most_recent_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d71de-e52d-4a24-91be-e025c757e5dd",
   "metadata": {},
   "source": [
    "### 4b. Func2: get order affiliate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d872f-f28c-4d62-b94f-0d326fc5225f",
   "metadata": {
    "tags": []
   },
   "source": [
    "4b1. Download excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "742767df-11e7-47df-8972-23430d7f3c85",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Order affiliate export completed\n",
      "2. Order affiliate download completed\n"
     ]
    }
   ],
   "source": [
    "# 1. Request a download file\n",
    "driver.get('https://affiliate.tiktok.com/product/order?shop_region=VN')\n",
    "\n",
    "with open(\"cookies_cerave.json\", \"r\") as f:\n",
    "        cookies = json.load(f)\n",
    "\n",
    "json_data = {\n",
    "    'conditions': {\n",
    "        'time_period': {\n",
    "            'beginning_time': str(min(df_time['unix_time_order_start'])) + '000',\n",
    "            'ending_time': str(max(df_time['unix_time_order_end'])) + '000',\n",
    "        },\n",
    "        'filter_type': 0,\n",
    "        'file_format': 0,\n",
    "        'product_id': '',\n",
    "    },\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    'https://affiliate.tiktok.com/api/v1/affiliate/export_order_v2'\n",
    "    cookies=cookies,\n",
    "    json=json_data,\n",
    "    verify=False\n",
    ")\n",
    "\n",
    "if response.text.find(\"success\") != -1: \n",
    "    print('1. Order affiliate export completed')\n",
    "else:     \n",
    "    print('1. Order affiliate export failed')\n",
    "\n",
    "time.sleep(5)    \n",
    "    \n",
    "# 2. Locate to download location and download file\n",
    "# click exported\n",
    "WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, \"//span[normalize-space()='Exported']\"))).click()\n",
    "# click download: only download if file is: ready to download and is a new file\n",
    "# ready to download\n",
    "while True: \n",
    "    ready_to_download = WebDriverWait(driver, 50).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[2]/span/div[1]/div/div/div/div/div/div[3]/div[1]/div[2]/button')))\n",
    "    if ready_to_download.get_attribute('disabled') == 'true':\n",
    "        pass\n",
    "    else: break\n",
    "# new file\n",
    "while True:\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '/html/body/div[2]/span/div[1]/div/div/div/div/div/div[3]/div[1]/div[2]/span')\n",
    "        break\n",
    "    except:    \n",
    "        pass\n",
    "    \n",
    "time.sleep(2)    \n",
    "WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[2]/span/div[1]/div/div/div/div/div/div[3]/div[1]/div[2]/button'))).click()\n",
    "if len(df_time) <= 10:\n",
    "    time.sleep(10)\n",
    "else:\n",
    "    time.sleep(20)\n",
    "print('2. Order affiliate download completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835914e-6d8e-4772-9d48-1ee2c5c13f6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "4b2. Locate to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c2a0934-0cc7-4259-ad19-df3524a8731e",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the list of all CSV files in the current directory\n",
    "csv_files = glob.glob(file_download_path + '/*.csv')\n",
    "\n",
    "# # Get the most recently downloaded CSV file\n",
    "most_recent_file = max(csv_files, key=os.path.getctime)\n",
    "\n",
    "# # Print the name of the most recently downloaded CSV file\n",
    "df_order_affiliate = pd.read_csv(most_recent_file, dtype={\n",
    "    'Content ID': 'string'\n",
    "    ,'Order ID': 'string'\n",
    "    ,'Product ID': 'string'\n",
    "    ,'Sku Id': 'string'\n",
    "})\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412ee45-4bda-4c41-8fcc-216d4bdd6c6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4c. Func3: get live stream data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95861d11-5217-480e-9fba-841df83551ef",
   "metadata": {
    "hide_input": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def get_data_livestream(x):\n",
    "    \n",
    "    with open(\"cookies_cerave.json\", \"r\") as f:\n",
    "        cookies = json.load(f)\n",
    "\n",
    "    json_data = {\n",
    "        'request': {\n",
    "            'params': [\n",
    "                {\n",
    "                    'list_control': {\n",
    "                        'pagination': {\n",
    "                            'size': 1000,\n",
    "                            'page': 0,\n",
    "                        },\n",
    "                        'rules': [\n",
    "                            {\n",
    "                                'direction': 2,\n",
    "                                'field': 'LIVE_LIST_START_TIMESTAMP',\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                    'filter': {\n",
    "                        'creator_id': [],\n",
    "                    },\n",
    "                    'time_selector': {\n",
    "                        'period': 20,\n",
    "                        'granularity': 1,\n",
    "                        'base_timestamp': int(x),\n",
    "                        'timezone_offset': 0,\n",
    "                    },\n",
    "                    'stats_types': [\n",
    "                        12,20,61,35,36,30,37,21,31,34,86,32,81,87,41,83,80,85,33,40,84,82,2,3,4,5,6,10,12,13,14,7,8,\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                'https://seller-vn.tiktok.com/api/v2/insights/seller/live/list,\n",
    "                cookies=cookies,\n",
    "                headers=headers,\n",
    "                json=json_data,\n",
    "                verify=False)\n",
    "            \n",
    "            data = response.json()\n",
    "    \n",
    "            global df_livestream\n",
    "\n",
    "            if 'stats' in data['data']['segments'][0]['timed_lists'][0]:\n",
    "                lst = data['data']['segments'][0]['timed_lists'][0]['stats']\n",
    "                df_livestream = pd.json_normalize(lst, max_level=0)\n",
    "            else:\n",
    "                df_livestream = pd.DataFrame(columns=['A'])\n",
    "        \n",
    "            break\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 3 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(3)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n",
    "\n",
    "def revenue_clean(x):\n",
    "    return x['amount']\n",
    "\n",
    "def avg_unit_price_clean(x):\n",
    "    return x['amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58602b0-59ac-4a03-aec3-fb0371c2a0df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4d. Func4: get video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e4e2b8-d243-4975-880a-cea8db8cc210",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_video(x):\n",
    "    \n",
    "    with open(\"cookies_cerave.json\", \"r\") as f:\n",
    "        cookies = json.load(f)\n",
    "\n",
    "    json_data = {\n",
    "        'request': {\n",
    "            'params': [\n",
    "                {\n",
    "                    'time_selector': {\n",
    "                        'period': 20,\n",
    "                        'granularity': 11,\n",
    "                        'base_timestamp': int(x),\n",
    "                        'timezone_offset': 0,\n",
    "                    },\n",
    "                    'list_control': {\n",
    "                        'rules': [\n",
    "                            {\n",
    "                                'direction': 2,\n",
    "                                'field': 'SHOP_VIDEO_LIST_REVENUE',\n",
    "                            },\n",
    "                        ],\n",
    "                        'pagination': {\n",
    "                            'size': 1000,\n",
    "                            'page': 0,\n",
    "                        },\n",
    "                    },\n",
    "                    'stats_types': [\n",
    "                        2,4,3,80,90,62,82,63,85,120,81,20,60,200,22,61,21,23,24,\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "  \n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                'https://seller-vn.tiktok.com/api/v2/insights/seller/shop/video/list'\n",
    "                cookies=cookies,\n",
    "                headers=headers,\n",
    "                json=json_data,\n",
    "                verify=False)\n",
    "            \n",
    "            data = response.json()\n",
    "    \n",
    "            global df_video\n",
    "\n",
    "            if 'stats' in data['data']['segments'][0]['timed_lists'][0]:\n",
    "                lst = data['data']['segments'][0]['timed_lists'][0]['stats']\n",
    "                df_video = pd.json_normalize(lst, max_level=0)\n",
    "            else:\n",
    "                df_video = pd.DataFrame(columns=['A'])\n",
    "        \n",
    "            break\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 3 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(3)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue    \n",
    "\n",
    "# 1. Clean creator        \n",
    "def creator_id(x): \n",
    "    if type(x) == float:\n",
    "        return None\n",
    "    else: return x['id']\n",
    "\n",
    "def creator_handle(x): \n",
    "    if type(x) == float:\n",
    "        return None\n",
    "    else: return x['handle']\n",
    "\n",
    "def creator_alias(x): \n",
    "    if type(x) == float:\n",
    "        return None\n",
    "    else: return x['alias']\n",
    "\n",
    "# 2. Clean video  \n",
    "def video_id(x): return x['id']\n",
    "\n",
    "def video_name(x): \n",
    "    match = re.search(r\"'name':\\s+'([^']*)'\", x)\n",
    "    match2 = re.search(r\"'name': \\\"(.*?)\\\"\", x)\n",
    "    if match:\n",
    "        name_value = match.group(1)\n",
    "        return name_value\n",
    "    elif match2:\n",
    "        name_value = match2.group(1)\n",
    "        return name_value\n",
    "\n",
    "def video_url(x): \n",
    "    match = re.search(r\"'main_url': '(.*?)'\", x)\n",
    "    if match:\n",
    "        name_value = match.group(1)\n",
    "        return name_value\n",
    "    \n",
    "def video_publish_time(x): \n",
    "    match = re.search(r\"'publish_time':\\s+(\\d+)\", x) \n",
    "    if match:\n",
    "        name_value = match.group(1)\n",
    "        return name_value   \n",
    "\n",
    "def video_duration(x): \n",
    "    match = re.search(r\"'duration':\\s+([0-9.]+)\", x)\n",
    "    if match:\n",
    "        duration_value = match.group(1)\n",
    "        return duration_value\n",
    "\n",
    "# 3. Clean number\n",
    "def video_revenue(x): return x['amount']\n",
    "def video_refunds(x): return x['amount']\n",
    "def video_commission_estimated(x): return x['amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf0408-0f6d-4118-917e-2e9be320962d",
   "metadata": {},
   "source": [
    "### 4e. Func5: get product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c015774-62d5-40cc-9293-b613a9c1b816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_product(x):\n",
    "    with open(\"cookies_cerave.json\", \"r\") as f:\n",
    "            cookies = json.load(f)\n",
    "\n",
    "    params = {\n",
    "        'locale': 'en',\n",
    "        'language': 'en',\n",
    "        'oec_seller_id': '7494854840010246582',\n",
    "        'aid': '4068',\n",
    "        'app_name': 'i18n_ecom_shop',\n",
    "    }\n",
    "    \n",
    "    json_data = {\n",
    "        'request': {\n",
    "            'params': [\n",
    "                {\n",
    "                    'stats_types': [\n",
    "                        10,21,20,23,11,30,37,120,1,33,38,32,34,121,12,40,47,220,41,43,48,42,44,221,2,4,3,270,\n",
    "                    ],\n",
    "                    'time_selector': {\n",
    "                        'period': 20,\n",
    "                        'granularity': 1,\n",
    "                        'base_timestamp': int(x),\n",
    "                        'timezone_offset': 0,\n",
    "                    },\n",
    "                    'search_filter': {\n",
    "                        'input': '',\n",
    "                    },\n",
    "                    'list_control': {\n",
    "                        'rules': [\n",
    "                            {\n",
    "                                'direction': 2,\n",
    "                                'field': 'SHOP_PRODUCT_LIST_REVENUE',\n",
    "                            },\n",
    "                        ],\n",
    "                        'pagination': {\n",
    "                            'size': 1000,\n",
    "                            'page': 0,\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        'https://seller-vn.tiktok.com/api/v2/insights/seller/shop/product/list',\n",
    "        params=params,\n",
    "        cookies=cookies,\n",
    "        json=json_data,\n",
    "        verify=False\n",
    "    )\n",
    "    data = response.json()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            if 'stats' in data['data']['segments'][0]['timed_lists'][0]:\n",
    "                lst = data['data']['segments'][0]['timed_lists'][0]['stats']\n",
    "                global df_product\n",
    "                df_product = pd.json_normalize(lst, max_level=0)\n",
    "                break\n",
    "            else:\n",
    "                columns = ['shop_id', 'product_id', 'product_name', 'product_image','revenue', 'revenue_live', 'revenue_video',\n",
    "                    'buyer_cnt', 'item_sold_cnt', 'sku_order_cnt','item_sold_live_cnt', 'buyer_live_cnt', 'viewer_live_cnt',\n",
    "                    'unique_item_click_live_cnt', 'product_view_cnt_live', 'product_click_cnt_live','item_sold_video_cnt'\n",
    "                    , 'sku_order_video_cnt', 'buyer_video_cnt','viewer_video_cnt', 'unique_item_click_video_cnt', 'product_view_cnt_video',\n",
    "                    'product_click_cnt_video', 'product_co_rate_live', 'product_ctr_rate_live','product_co_rate_video', 'product_ctr_rate_video']\n",
    "                \n",
    "                df_product = pd.DataFrame(columns=columns)\n",
    "                break\n",
    "        except:\n",
    "            print(\"Connection refused by the server..\")\n",
    "            print(\"Let me sleep for 3 seconds\")\n",
    "            print(\"ZZzzzz...\")\n",
    "            time.sleep(3)\n",
    "            print(\"Was a nice sleep, now let me continue...\")\n",
    "            continue\n",
    "            \n",
    "def get_product_image(x): return x['thumb_url_list'][0]\n",
    "def get_product_revenue(x): return x['amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ee7cd-a2a6-4b53-8b5c-10d4a3cdde10",
   "metadata": {},
   "source": [
    "## 5. Data sample of live stream + video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d1d155-6a5f-4fab-bea1-9ab0435075c8",
   "metadata": {},
   "source": [
    "### 5a. Live stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ffaac96-56a3-48d7-aa31-d553f016bf61",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator_id</th>\n",
       "      <th>creator_handle</th>\n",
       "      <th>creator_alias</th>\n",
       "      <th>creator_avatar</th>\n",
       "      <th>creator_type</th>\n",
       "      <th>is_commissioned</th>\n",
       "      <th>creator_bind_shop_country</th>\n",
       "      <th>live_id</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>revenue</th>\n",
       "      <th>avg_unit_price</th>\n",
       "      <th>products_cnt</th>\n",
       "      <th>products_with_sales_cnt</th>\n",
       "      <th>product_views_cnt</th>\n",
       "      <th>product_clicks_cnt</th>\n",
       "      <th>items_sold_cnt</th>\n",
       "      <th>buyers_cnt</th>\n",
       "      <th>orders_created_cnt</th>\n",
       "      <th>orders_paid_cnt</th>\n",
       "      <th>avg_concurrent_users_cnt</th>\n",
       "      <th>peak_concurrent_users_cnt</th>\n",
       "      <th>co_rate</th>\n",
       "      <th>local_avg_watch_duration</th>\n",
       "      <th>local_ctr_rate</th>\n",
       "      <th>local_new_followers_cnt</th>\n",
       "      <th>local_shares_cnt</th>\n",
       "      <th>local_comments_cnt</th>\n",
       "      <th>local_likes_cnt</th>\n",
       "      <th>local_views_cnt</th>\n",
       "      <th>local_viewers_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7225492401526703109</td>\n",
       "      <td>nt.anhhh</td>\n",
       "      <td>Ánh đâyy</td>\n",
       "      <td>{'thumb_url_list': ['https://p16-sign-sg.tikto...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>7313957381220666130</td>\n",
       "      <td>1702913411</td>\n",
       "      <td>1702919476</td>\n",
       "      <td>6065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>547</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>868</td>\n",
       "      <td>1157</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7022862578805097499</td>\n",
       "      <td>khongcosonchannel</td>\n",
       "      <td>Quỳnh Như Khongcoson</td>\n",
       "      <td>{'thumb_url_list': ['https://p16-sign-sg.tikto...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>7313938758980717320</td>\n",
       "      <td>1702909077</td>\n",
       "      <td>1702920393</td>\n",
       "      <td>11316</td>\n",
       "      <td>358000</td>\n",
       "      <td>358000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4316</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>272</td>\n",
       "      <td>520</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>103</td>\n",
       "      <td>15</td>\n",
       "      <td>1750</td>\n",
       "      <td>17833</td>\n",
       "      <td>29509</td>\n",
       "      <td>22491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            creator_id     creator_handle         creator_alias  \\\n",
       "0  7225492401526703109           nt.anhhh              Ánh đâyy   \n",
       "1  7022862578805097499  khongcosonchannel  Quỳnh Như Khongcoson   \n",
       "\n",
       "                                      creator_avatar  creator_type  \\\n",
       "0  {'thumb_url_list': ['https://p16-sign-sg.tikto...             3   \n",
       "1  {'thumb_url_list': ['https://p16-sign-sg.tikto...             3   \n",
       "\n",
       "   is_commissioned creator_bind_shop_country              live_id  \\\n",
       "0            False                            7313957381220666130   \n",
       "1            False                            7313938758980717320   \n",
       "\n",
       "   start_timestamp  end_timestamp  duration revenue avg_unit_price  \\\n",
       "0       1702913411     1702919476      6065       0              0   \n",
       "1       1702909077     1702920393     11316  358000         358000   \n",
       "\n",
       "   products_cnt  products_with_sales_cnt  product_views_cnt  \\\n",
       "0             4                        0                547   \n",
       "1             2                        1               4316   \n",
       "\n",
       "   product_clicks_cnt  items_sold_cnt  buyers_cnt  orders_created_cnt  \\\n",
       "0                  16               0           0                   0   \n",
       "1                  50               1           1                   1   \n",
       "\n",
       "   orders_paid_cnt  avg_concurrent_users_cnt  peak_concurrent_users_cnt  \\\n",
       "0                0                         5                         17   \n",
       "1                1                       272                        520   \n",
       "\n",
       "  co_rate  local_avg_watch_duration local_ctr_rate  local_new_followers_cnt  \\\n",
       "0  0.0000                        20         0.0138                        4   \n",
       "1  0.0200                        52         0.0017                      103   \n",
       "\n",
       "   local_shares_cnt  local_comments_cnt  local_likes_cnt  local_views_cnt  \\\n",
       "0                 0                  43              868             1157   \n",
       "1                15                1750            17833            29509   \n",
       "\n",
       "   local_viewers_cnt  \n",
       "0               1016  \n",
       "1              22491  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a sample live stream data of 16/07/2023\n",
    "get_data_livestream(max(df_time['unix_time']))\n",
    "df_livestream2 = df_livestream.copy()\n",
    "df_livestream2['revenue'] = df_livestream2['revenue'].apply(revenue_clean)\n",
    "df_livestream2['avg_unit_price'] = df_livestream2['avg_unit_price'].apply(avg_unit_price_clean)\n",
    "df_livestream2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7264a56-54f1-4757-80cf-4de7a2e477ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5b. Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c594f8d-6d0c-4861-b564-3d310a7f9f5a",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Get a sample live stream data of 16/07/2023\n",
    "get_data_video(max(df_time['unix_time']))\n",
    "df_video2 = df_video.copy()    \n",
    "df_video2['creator_id'] = df_video2['creator_meta'].apply(creator_id)\n",
    "df_video2['creator_handle'] = df_video2['creator_meta'].apply(creator_handle)\n",
    "df_video2['creator_alias'] = df_video2['creator_meta'].apply(creator_alias)\n",
    "df_video2['video_id'] = df_video2['video_meta'].apply(video_id)\n",
    "df_video2['video_raw'] = df_video2['video_meta'].astype(str)\n",
    "df_video2['video_name'] = df_video2['video_raw'].apply(video_name)\n",
    "df_video2['video_url'] = df_video2['video_raw'].apply(video_url)\n",
    "df_video2['video_publish_time'] = df_video2['video_raw'].apply(video_publish_time)\n",
    "df_video2['duration'] = df_video2['video_raw'].apply(video_duration)\n",
    "df_video2['revenue'] = df_video2['revenue'].apply(video_revenue)\n",
    "df_video2['refunds'] = df_video2['refunds'].apply(video_refunds)\n",
    "df_video2['commission_estimated'] = df_video2['commission_estimated'].apply(video_commission_estimated)\n",
    "df_video2 = df_video2.drop(columns=['creator_meta', 'video_meta','product_metas','video_raw'])\n",
    "df_video2 = df_video2.loc[:,['video_id', 'video_name', 'video_url', 'video_publish_time', 'duration', 'creator_id', 'creator_handle', 'creator_alias', 'view_cnt', 'like_cnt', 'comment_cnt', 'share_cnt', 'new_follower_cnt', 'item_exposure_cnt', 'item_click_cnt', 'item_sold_cnt', 'item_buyer_cnt', 'revenue', 'refunds', 'commission_estimated', 'product_refund_item_cnt', 'co_rate', 'sku_order_created_cnt', 'ctr_rate']]\n",
    "df_video2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8506c9b1-b91c-4aca-9ec0-cec9b908dcb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5c. Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1ed22-40a9-4d90-b26e-af420f33c6b1",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_order.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219ad4e-4f47-4e45-8e7c-96d2c486cfbe",
   "metadata": {},
   "source": [
    "### 5d. Order afiliate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293ac7e-25cd-4200-ae39-375286851a8e",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_order_affiliate.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215ae6c-72a5-47f5-bbae-db78803aa15d",
   "metadata": {},
   "source": [
    "### 5e. Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baecc92-d17e-4189-a247-410a8f568dcb",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_data_product(max(df_time['unix_time']))\n",
    "df_product['product_image'] = df_product['product_image'].apply(get_product_image)\n",
    "df_product['revenue'] = df_product['revenue'].apply(get_product_revenue)\n",
    "df_product['revenue_live'] = df_product['revenue_live'].apply(get_product_revenue)\n",
    "df_product['revenue_video'] = df_product['revenue_video'].apply(get_product_revenue)\n",
    "df_product.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e05401b-613e-4e33-9bf7-495f11c9e9cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Run while loop to get data of all date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59318f04-e888-4637-9cf6-60dbb1dec901",
   "metadata": {},
   "source": [
    "### 6a. Run while loop to get data of livestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6282c613-1b42-4f99-996e-9424522e3dc3",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_livestream_final():\n",
    "    \n",
    "    df_livestream_final = pd.DataFrame(columns = ['creator_id', 'creator_handle', 'creator_alias', 'creator_avatar'\n",
    "                                   , 'creator_type', 'is_commissioned', 'creator_bind_shop_country', 'live_id'\n",
    "                                   , 'start_timestamp', 'end_timestamp', 'duration', 'revenue', 'avg_unit_price'\n",
    "                                   , 'products_cnt', 'products_with_sales_cnt', 'product_views_cnt'\n",
    "                                   , 'product_clicks_cnt', 'items_sold_cnt', 'buyers_cnt', 'orders_created_cnt'\n",
    "                                   , 'orders_paid_cnt', 'avg_concurrent_users_cnt', 'peak_concurrent_users_cnt'\n",
    "                                   , 'co_rate', 'local_avg_watch_duration', 'local_ctr_rate'\n",
    "                                   , 'local_new_followers_cnt', 'local_shares_cnt', 'local_comments_cnt'\n",
    "                                   , 'local_likes_cnt', 'local_views_cnt', 'local_viewers_cnt'])\n",
    "    \n",
    "    for i in range(len(df_time)):\n",
    "        x = df_time.loc[i, \"date_scrape\"]\n",
    "        y = df_time.loc[i, \"unix_time\"]\n",
    "\n",
    "        # 1. get data\n",
    "        get_data_livestream(y)\n",
    "\n",
    "        # 2. Check if scrape data has any rows\n",
    "        if len(df_livestream) > 0:\n",
    "\n",
    "            # 3. clean data\n",
    "            df2 = df_livestream.copy()\n",
    "            df2['revenue'] = df2['revenue'].apply(revenue_clean)\n",
    "            df2['avg_unit_price'] = df2['avg_unit_price'].apply(avg_unit_price_clean)\n",
    "\n",
    "            # 4. add column date scrape to df\n",
    "            df2['date_scrape'] = x   \n",
    "            df2 = df2.astype({\"is_commissioned\": str})\n",
    "            df_livestream_final = pd.concat([df_livestream_final, df2])\n",
    "\n",
    "            # 5. Do nothing if scrape data do not have any rows\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('Done scrape livestream for day ' + str(x))\n",
    "\n",
    "    file_path = \"{}/Livestream/\".format(file_save_path)\n",
    "    file_name = \"{}_tiktok_livestream_\".format(brand) + str(start_date).replace('-','_') + \".xlsx\"\n",
    "    out_path = file_path + file_name\n",
    "    writer = pd.ExcelWriter(out_path , engine='xlsxwriter')\n",
    "    df_livestream_final.set_index('creator_id', inplace=True)\n",
    "    df_livestream_final = df_livestream_final.drop(columns=['creator_avatar'])  # ===> exclude some columns\n",
    "    df_livestream_final.to_excel(writer, sheet_name='Sheet1')\n",
    "    writer.close()\n",
    "    print('Complete scraping livestream ' + '\\n' +\n",
    "          'File name: ' + file_name + '\\n' +\n",
    "          'File path: ' + out_path + '\\n')\n",
    "    \n",
    "# get_livestream_final()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd6571-d06e-4cef-80bc-8d1971a7ddeb",
   "metadata": {},
   "source": [
    "### 6b. Run while loop to get data of video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "148a33c2-a940-4951-a911-61f70f1ebb1c",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_video_final():\n",
    "    \n",
    "    df_video_final = pd.DataFrame(columns = ['video_id', 'video_name', 'video_url', 'video_publish_time', 'duration'\n",
    "                                             , 'creator_id', 'creator_handle', 'creator_alias', 'view_cnt', 'like_cnt'\n",
    "                                             , 'comment_cnt', 'share_cnt', 'new_follower_cnt', 'item_exposure_cnt'\n",
    "                                             , 'item_click_cnt', 'item_sold_cnt', 'item_buyer_cnt', 'revenue', 'refunds'\n",
    "                                             , 'commission_estimated', 'product_refund_item_cnt', 'co_rate'\n",
    "                                             , 'sku_order_created_cnt', 'ctr_rate'])\n",
    "    \n",
    "    for i in range(len(df_time)):\n",
    "        x = df_time.loc[i, \"date_scrape\"]\n",
    "        y = df_time.loc[i, \"unix_time\"]\n",
    "\n",
    "        # 1. get data\n",
    "        get_data_video(y)\n",
    "\n",
    "        # 2. Check if scrape data has any rows\n",
    "        if len(df_video) > 0:\n",
    "\n",
    "            # 3. clean data\n",
    "            df_video2 = df_video.copy()    \n",
    "            df_video2['creator_id'] = df_video2['creator_meta'].apply(creator_id)\n",
    "            df_video2['creator_handle'] = df_video2['creator_meta'].apply(creator_handle)\n",
    "            df_video2['creator_alias'] = df_video2['creator_meta'].apply(creator_alias)\n",
    "            df_video2['video_id'] = df_video2['video_meta'].apply(video_id)\n",
    "            df_video2['video_raw'] = df_video2['video_meta'].astype(str)\n",
    "            df_video2['video_name'] = df_video2['video_raw'].apply(video_name)\n",
    "            df_video2['video_url'] = df_video2['video_raw'].apply(video_url)\n",
    "            df_video2['video_publish_time'] = df_video2['video_raw'].apply(video_publish_time)\n",
    "            df_video2['duration'] = df_video2['video_raw'].apply(video_duration)\n",
    "            df_video2['revenue'] = df_video2['revenue'].apply(video_revenue)\n",
    "            df_video2['refunds'] = df_video2['refunds'].apply(video_refunds)\n",
    "            df_video2['commission_estimated'] = df_video2['commission_estimated'].apply(video_commission_estimated)\n",
    "            df_video2 = df_video2.drop(columns=['creator_meta', 'video_meta','product_metas','video_raw'])\n",
    "            df_video2 = df_video2.loc[:,['video_id', 'video_name', 'video_url', 'video_publish_time', 'duration', 'creator_id', 'creator_handle', 'creator_alias', 'view_cnt', 'like_cnt', 'comment_cnt', 'share_cnt', 'new_follower_cnt', 'item_exposure_cnt', 'item_click_cnt', 'item_sold_cnt', 'item_buyer_cnt', 'revenue', 'refunds', 'commission_estimated', 'product_refund_item_cnt', 'co_rate', 'sku_order_created_cnt', 'ctr_rate']]\n",
    "\n",
    "            # 4. add column date scrape to df\n",
    "            df_video2['date_scrape'] = x   \n",
    "            df_video_final = pd.concat([df_video_final, df_video2])\n",
    "\n",
    "            # 5. Do nothing if scrape data do not have any rows\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('Done scrape video for day ' + str(x))\n",
    "\n",
    "    file_path = \"{}/Video/\".format(file_save_path)\n",
    "    file_name = \"{}_tiktok_video_\".format(brand) + str(start_date).replace('-','_') + \".xlsx\"\n",
    "    out_path = file_path + file_name\n",
    "    writer = pd.ExcelWriter(out_path , engine='xlsxwriter')\n",
    "    df_video_final.set_index('video_id', inplace=True)\n",
    "    df_video_final.to_excel(writer, sheet_name='Sheet1')\n",
    "    writer.close()\n",
    "    print('Complete scraping Video ' + '\\n' +\n",
    "          'File name: ' + file_name + '\\n' +\n",
    "          'File path: ' + out_path + '\\n')\n",
    "    \n",
    "# get_video_final()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a3e45-f870-4e01-8802-086e83114737",
   "metadata": {},
   "source": [
    "### 6c. Parse Order data to excel folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5653ace-5dbd-4ce5-9347-e69cfd1d858a",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_order_final():\n",
    "    file_path = \"{}/Orders/\".format(file_save_path)\n",
    "    file_name = \"{}_tiktok_orders_\".format(brand) + str(start_date).replace('-','_') + \".xlsx\"\n",
    "    out_path = file_path + file_name\n",
    "    writer = pd.ExcelWriter(out_path , engine='xlsxwriter')\n",
    "    df_order1 = df_order.copy()\n",
    "    df_order1['Order ID'] = df_order1['Order ID'].astype(str)\n",
    "    df_order1['SKU ID'] = df_order1['SKU ID'].astype(str)\n",
    "    df_order1.set_index('Order ID', inplace=True)\n",
    "    df_order1.to_excel(writer, sheet_name='Sheet1')\n",
    "    writer.close()\n",
    "    print('Complete scraping orders ' + '\\n' +\n",
    "          'File name: ' + file_name + '\\n' +\n",
    "          'File path: ' + out_path + '\\n')\n",
    "    \n",
    "# get_order_final()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a17274-49d1-46ec-8db6-a6dc5f987104",
   "metadata": {},
   "source": [
    "### 6d. Run while loop to get data of affiliate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f6614b6-786b-46a3-a690-f2d8c0f98275",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def get_order_affiliate_final():\n",
    "    file_path = \"{}/Affiliate Orders/\".format(file_save_path)\n",
    "    file_name = \"{}_tiktok_affiliate_orders_\".format(brand) + str(start_date).replace('-','_') + \".xlsx\"\n",
    "    out_path = file_path + file_name\n",
    "    writer = pd.ExcelWriter(out_path , engine='xlsxwriter')\n",
    "    df_order_affiliate.set_index('Order ID', inplace=True)\n",
    "    df_order_affiliate.to_excel(writer, sheet_name='Sheet1')\n",
    "    writer.close()\n",
    "    print('Complete scraping affiliate orders ' + '\\n' +\n",
    "          'File name: ' + file_name + '\\n' +\n",
    "          'File path: ' + out_path + '\\n')\n",
    "    \n",
    "# get_order_affiliate_final()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d71beac-e554-435b-8eca-4e7915bc7d85",
   "metadata": {},
   "source": [
    "### 6e. Run while loop to get data of product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cef53668-fd19-41ed-be82-9e05598fd3f1",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_product_final():\n",
    "    \n",
    "    df_product_final = pd.DataFrame(columns = ['shop_id', 'product_id', 'product_name', 'product_image', 'revenue', 'revenue_live'\n",
    "                                               , 'revenue_video', 'buyer_cnt', 'item_sold_cnt', 'sku_order_cnt', 'item_sold_live_cnt'\n",
    "                                               , 'buyer_live_cnt', 'viewer_live_cnt', 'unique_item_click_live_cnt'\n",
    "                                               , 'product_view_cnt_live', 'product_click_cnt_live', 'item_sold_video_cnt'\n",
    "                                               , 'sku_order_video_cnt', 'buyer_video_cnt', 'viewer_video_cnt'\n",
    "                                               , 'unique_item_click_video_cnt', 'product_view_cnt_video', 'product_click_cnt_video'\n",
    "                                               , 'product_co_rate_live', 'product_ctr_rate_live', 'product_co_rate_video'\n",
    "                                               , 'product_ctr_rate_video'])\n",
    "    \n",
    "    for i in range(len(df_time)):\n",
    "        x = df_time.loc[i, \"date_scrape\"]\n",
    "        y = df_time.loc[i, \"unix_time\"]\n",
    "\n",
    "        # 1. get data\n",
    "        get_data_product(y)\n",
    "\n",
    "        # 2. Check if scrape data has any rows\n",
    "        if len(df_product) > 0:\n",
    "\n",
    "            # 3. clean data\n",
    "            df_product2 = df_product.copy()    \n",
    "            df_product2['product_image'] = df_product['product_image'].apply(get_product_image)\n",
    "            df_product2['revenue'] = df_product2['revenue'].apply(get_product_revenue)\n",
    "            df_product2['revenue_live'] = df_product2['revenue_live'].apply(get_product_revenue)\n",
    "            df_product2['revenue_video'] = df_product2['revenue_video'].apply(get_product_revenue)\n",
    "\n",
    "            # 4. add column date scrape to df\n",
    "            df_product2['date_scrape'] = x   \n",
    "            df_product_final = pd.concat([df_product_final, df_product2])\n",
    "\n",
    "            # 5. Do nothing if scrape data do not have any rows\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('Done scrape product for day ' + str(x))\n",
    "\n",
    "    file_path = \"{}/Product/\".format(file_save_path)\n",
    "    file_name = \"{}_tiktok_product_\".format(brand) + str(start_date).replace('-','_') + \".xlsx\"\n",
    "    out_path = file_path + file_name\n",
    "    writer = pd.ExcelWriter(out_path , engine='xlsxwriter')\n",
    "    df_product_final.set_index('product_id', inplace=True)\n",
    "    df_product_final.to_excel(writer, sheet_name='Sheet1')\n",
    "    writer.close()\n",
    "    print('Complete scraping Product ' + '\\n' +\n",
    "          'File name: ' + file_name + '\\n' +\n",
    "          'File path: ' + out_path)\n",
    "    \n",
    "# get_product_final()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a63890d-d263-4457-8f26-b28486a7f23c",
   "metadata": {
    "hide_input": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Start scraping livestream: \n",
      "Done scrape livestream for day 2023-12-01\n",
      "Done scrape livestream for day 2023-12-02\n",
      "Done scrape livestream for day 2023-12-03\n",
      "Done scrape livestream for day 2023-12-04\n",
      "Done scrape livestream for day 2023-12-05\n",
      "Done scrape livestream for day 2023-12-06\n",
      "Done scrape livestream for day 2023-12-07\n",
      "Done scrape livestream for day 2023-12-08\n",
      "Done scrape livestream for day 2023-12-09\n",
      "Done scrape livestream for day 2023-12-10\n",
      "Done scrape livestream for day 2023-12-11\n",
      "Done scrape livestream for day 2023-12-12\n",
      "Done scrape livestream for day 2023-12-13\n",
      "Done scrape livestream for day 2023-12-14\n",
      "Done scrape livestream for day 2023-12-15\n",
      "Done scrape livestream for day 2023-12-16\n",
      "Done scrape livestream for day 2023-12-17\n",
      "Complete scraping livestream \n",
      "File name: cerave_tiktok_livestream_2023_12_01.xlsx\n",
      "File path: C:/Users/gianhubinh.le/OneDrive - L'Oréal/Documents - -VN- Data Hub - Analytics/Tiktok Shop/Test/Livestream/cerave_tiktok_livestream_2023_12_01.xlsx\n",
      "\n",
      "2. Start scraping video: \n",
      "Done scrape video for day 2023-12-01\n",
      "Done scrape video for day 2023-12-02\n",
      "Done scrape video for day 2023-12-03\n",
      "Done scrape video for day 2023-12-04\n",
      "Done scrape video for day 2023-12-05\n",
      "Done scrape video for day 2023-12-06\n",
      "Done scrape video for day 2023-12-07\n",
      "Done scrape video for day 2023-12-08\n",
      "Done scrape video for day 2023-12-09\n",
      "Done scrape video for day 2023-12-10\n",
      "Done scrape video for day 2023-12-11\n",
      "Done scrape video for day 2023-12-12\n",
      "Done scrape video for day 2023-12-13\n",
      "Done scrape video for day 2023-12-14\n",
      "Done scrape video for day 2023-12-15\n",
      "Done scrape video for day 2023-12-16\n",
      "Done scrape video for day 2023-12-17\n",
      "Complete scraping Video \n",
      "File name: cerave_tiktok_video_2023_12_01.xlsx\n",
      "File path: C:/Users/gianhubinh.le/OneDrive - L'Oréal/Documents - -VN- Data Hub - Analytics/Tiktok Shop/Test/Video/cerave_tiktok_video_2023_12_01.xlsx\n",
      "\n",
      "3. Start scraping Orders: \n",
      "Complete scraping orders \n",
      "File name: cerave_tiktok_orders_2023_12_01.xlsx\n",
      "File path: C:/Users/gianhubinh.le/OneDrive - L'Oréal/Documents - -VN- Data Hub - Analytics/Tiktok Shop/Test/Orders/cerave_tiktok_orders_2023_12_01.xlsx\n",
      "\n",
      "4. Start scraping Affiliate orders: \n",
      "Complete scraping affiliate orders \n",
      "File name: cerave_tiktok_affiliate_orders_2023_12_01.xlsx\n",
      "File path: C:/Users/gianhubinh.le/OneDrive - L'Oréal/Documents - -VN- Data Hub - Analytics/Tiktok Shop/Test/Affiliate Orders/cerave_tiktok_affiliate_orders_2023_12_01.xlsx\n",
      "\n",
      "5. Start scraping Product: \n",
      "Done scrape product for day 2023-12-01\n",
      "Done scrape product for day 2023-12-02\n",
      "Done scrape product for day 2023-12-03\n",
      "Done scrape product for day 2023-12-04\n",
      "Done scrape product for day 2023-12-05\n",
      "Done scrape product for day 2023-12-06\n",
      "Done scrape product for day 2023-12-07\n",
      "Done scrape product for day 2023-12-08\n",
      "Done scrape product for day 2023-12-09\n",
      "Done scrape product for day 2023-12-10\n",
      "Done scrape product for day 2023-12-11\n",
      "Done scrape product for day 2023-12-12\n",
      "Done scrape product for day 2023-12-13\n",
      "Done scrape product for day 2023-12-14\n",
      "Done scrape product for day 2023-12-15\n",
      "Done scrape product for day 2023-12-16\n",
      "Done scrape product for day 2023-12-17\n",
      "Complete scraping Product \n",
      "File name: cerave_tiktok_product_2023_12_01.xlsx\n",
      "File path: C:/Users/gianhubinh.le/OneDrive - L'Oréal/Documents - -VN- Data Hub - Analytics/Tiktok Shop/Test/Product/cerave_tiktok_product_2023_12_01.xlsx\n"
     ]
    }
   ],
   "source": [
    "if '1' in domain:\n",
    "    print('1. Start scraping livestream: ')\n",
    "    get_livestream_final()  \n",
    "if '2' in domain:\n",
    "    print('2. Start scraping video: ')\n",
    "    get_video_final()  \n",
    "if '3' in domain:     \n",
    "    print('3. Start scraping Orders: ')\n",
    "    get_order_final()\n",
    "if '4' in domain:     \n",
    "    print('4. Start scraping Affiliate orders: ')\n",
    "    get_order_affiliate_final()\n",
    "if '5' in domain:     \n",
    "    print('5. Start scraping Product: ')\n",
    "    get_product_final()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
